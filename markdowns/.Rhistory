rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
source('/Users/nickwawee/Desktop/BGSU/MSA_6440/Week_2/myfunctions.R')
library(caret)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
source('/Users/nickwawee/Desktop/BGSU/MSA_6440/Week_2/myfunctions.R')
library(caret)
library(lattice)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
source('/Users/nickwawee/Desktop/BGSU/MSA_6440/Week_2/myfunctions.R')
library(caret)
library(ada)
library(mlearning)
library(plyr)
plot_cm = function(confusion){#https://gist.github.com/ctokheim/c3ab56a4db7311487761
tile <- ggplot() + geom_tile(aes(x=Actual, y=Predicted, fill=Percent),
data=confusion, color="black",size=0.1) +
labs(x="Actual",y="Predicted") +  # axis labels
opts(axis.text.x = theme_text(angle=-90))  # rotate axis ticks text
tile <- tile + geom_text(aes(x=Actual,y=Predicted, label=sprintf("%.1f", Percent)),
data=confusion, size=3, colour="black") +
scale_fill_gradient(low="grey",high="red")  # low pcts are grey, high pcts are red
tile <- tile + geom_tile(aes(x=Actual,y=Predicted),
data=subset(confusion, as.character(Actual)==as.character(Predicted)),
color="black", size=0.3, fill="black", alpha=0)
return(tile)
}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
source('/Users/nickwawee/Desktop/BGSU/MSA_6440/Week_2/myfunctions.R')
library(caret)
library(ada)
require(mlearning)
library(plyr)
plot_cm = function(confusion){#https://gist.github.com/ctokheim/c3ab56a4db7311487761
tile <- ggplot() + geom_tile(aes(x=Actual, y=Predicted, fill=Percent),
data=confusion, color="black",size=0.1) +
labs(x="Actual",y="Predicted") +  # axis labels
opts(axis.text.x = theme_text(angle=-90))  # rotate axis ticks text
tile <- tile + geom_text(aes(x=Actual,y=Predicted, label=sprintf("%.1f", Percent)),
data=confusion, size=3, colour="black") +
scale_fill_gradient(low="grey",high="red")  # low pcts are grey, high pcts are red
tile <- tile + geom_tile(aes(x=Actual,y=Predicted),
data=subset(confusion, as.character(Actual)==as.character(Predicted)),
color="black", size=0.3, fill="black", alpha=0)
return(tile)
}
bank = read.csv('../data/processed/BankChurners_filtered.csv', stringsAsFactors = T)
# Creating dummy variables for Education
bank$High_School <- ifelse(bank$Education_Level == 'High School', 1, 0)
bank$College <- ifelse(bank$Education_Level == 'College', 1, 0)
bank$Graduate <- ifelse(bank$Education_Level == 'Graduate', 1, 0)
bank$Uneducated <- ifelse(bank$Education_Level == 'Uneducated', 1, 0)
bank$Post_Graduate <- ifelse(bank$Education_Level == 'Post-Graduate', 1, 0)
bank$Doctorate <- ifelse(bank$Education_Level == 'Doctorate', 1, 0)
# Creating dummy variables for Marital Status
bank$Married <- ifelse(bank$Marital_Status == 'Married', 1, 0)
bank$Single <- ifelse(bank$Marital_Status == 'Single', 1, 0)
bank$Divorced <- ifelse(bank$Marital_Status == 'Divorced', 1, 0)
# Creating dummy variables for Gender
bank$Male <- ifelse(bank$Gender == 'M', 1, 0)
bank$Female <- ifelse(bank$Gender == 'F', 1, 0)
# Creating dummy variables for Income
bank$Income_5 <- ifelse(bank$Income_Category == '$120K +', 1, 0)
bank$Income_4 <- ifelse(bank$Income_Category == '$80K - $120K', 1, 0)
bank$Income_3 <- ifelse(bank$Income_Category == '$60K - $80K', 1, 0)
bank$Income_2 <- ifelse(bank$Income_Category == '$40K - $60K', 1, 0)
bank$Income_1 <- ifelse(bank$Income_Category == 'Less than $40K', 1, 0)
#Creating dummy variables for Card category
bank$Blue_Card <- ifelse(bank$Card_Category == 'Blue', 1, 0)
bank$Gold_Card <- ifelse(bank$Card_Category == 'Gold', 1, 0)
bank$Plat_Card <- ifelse(bank$Card_Category == 'Platinum', 1, 0)
bank$Silver_Card <- ifelse(bank$Card_Category == 'Silver', 1, 0)
bank <- bank[,c(-1,-2,-5,-7:-10)]
RNGkind (sample.kind = "Rounding")
set.seed(0)
dfls = partition.2(bank, 0.7)
test.data = dfls$data.test
training.data = dfls$data.train
set.seed(0)
modelLookup("rf")
train_control <- trainControl(method="cv", number=10)
rf <- train(Attrition_Flag ~ ., data = training.data, method = "rf", ntree = 50,rControl = train_control, tuneGrid = expand.grid(mtry = c(2,5,8)), metric = 'Kappa')
print(rf)
plot(varImp(rf))
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
source('/Users/nickwawee/Desktop/BGSU/MSA_6440/Week_2/myfunctions.R')
library(caret)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
source('/Users/nickwawee/Desktop/BGSU/MSA_6440/Week_2/myfunctions.R')
library(caret)
library(ada)
library(plyr)
plot_cm = function(confusion){#https://gist.github.com/ctokheim/c3ab56a4db7311487761
tile <- ggplot() + geom_tile(aes(x=Actual, y=Predicted, fill=Percent),
data=confusion, color="black",size=0.1) +
labs(x="Actual",y="Predicted") +  # axis labels
opts(axis.text.x = theme_text(angle=-90))  # rotate axis ticks text
tile <- tile + geom_text(aes(x=Actual,y=Predicted, label=sprintf("%.1f", Percent)),
data=confusion, size=3, colour="black") +
scale_fill_gradient(low="grey",high="red")  # low pcts are grey, high pcts are red
tile <- tile + geom_tile(aes(x=Actual,y=Predicted),
data=subset(confusion, as.character(Actual)==as.character(Predicted)),
color="black", size=0.3, fill="black", alpha=0)
return(tile)
}
bank = read.csv('../data/processed/BankChurners_filtered.csv', stringsAsFactors = T)
# Creating dummy variables for Education
bank$High_School <- ifelse(bank$Education_Level == 'High School', 1, 0)
bank$College <- ifelse(bank$Education_Level == 'College', 1, 0)
bank$Graduate <- ifelse(bank$Education_Level == 'Graduate', 1, 0)
bank$Uneducated <- ifelse(bank$Education_Level == 'Uneducated', 1, 0)
bank$Post_Graduate <- ifelse(bank$Education_Level == 'Post-Graduate', 1, 0)
bank$Doctorate <- ifelse(bank$Education_Level == 'Doctorate', 1, 0)
# Creating dummy variables for Marital Status
bank$Married <- ifelse(bank$Marital_Status == 'Married', 1, 0)
bank$Single <- ifelse(bank$Marital_Status == 'Single', 1, 0)
bank$Divorced <- ifelse(bank$Marital_Status == 'Divorced', 1, 0)
# Creating dummy variables for Gender
bank$Male <- ifelse(bank$Gender == 'M', 1, 0)
bank$Female <- ifelse(bank$Gender == 'F', 1, 0)
# Creating dummy variables for Income
bank$Income_5 <- ifelse(bank$Income_Category == '$120K +', 1, 0)
bank$Income_4 <- ifelse(bank$Income_Category == '$80K - $120K', 1, 0)
bank$Income_3 <- ifelse(bank$Income_Category == '$60K - $80K', 1, 0)
bank$Income_2 <- ifelse(bank$Income_Category == '$40K - $60K', 1, 0)
bank$Income_1 <- ifelse(bank$Income_Category == 'Less than $40K', 1, 0)
#Creating dummy variables for Card category
bank$Blue_Card <- ifelse(bank$Card_Category == 'Blue', 1, 0)
bank$Gold_Card <- ifelse(bank$Card_Category == 'Gold', 1, 0)
bank$Plat_Card <- ifelse(bank$Card_Category == 'Platinum', 1, 0)
bank$Silver_Card <- ifelse(bank$Card_Category == 'Silver', 1, 0)
bank <- bank[,c(-1,-2,-5,-7:-10)]
RNGkind (sample.kind = "Rounding")
set.seed(0)
dfls = partition.2(bank, 0.7)
test.data = dfls$data.test
training.data = dfls$data.train
set.seed(0)
modelLookup("rf")
train_control <- trainControl(method="cv", number=10)
rf <- train(Attrition_Flag ~ ., data = training.data, method = "rf", ntree = 50,rControl = train_control, tuneGrid = expand.grid(mtry = c(2,5,8)), metric = 'Kappa')
print(rf)
plot(varImp(rf))
rf$finalModel
# get prediction on the test data
pred.test.rf = predict(rf$finalModel, test.data, type = 'class')
# create confusion matrix
cm = confusionMatrix(pred.test.rf, test.data$Attrition_Flag, positive = "Attrited Customer")
confusion = data.frame(cm)
cm
View(cm)
cm[["table"]]
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
source('/Users/nickwawee/Desktop/BGSU/MSA_6440/Week_2/myfunctions.R')
library(caret)
library(ada)
library(plyr)
plot_cm <- function(cm) {#https://stackoverflow.com/questions/23891140/r-how-to-visualize-confusion-matrix-using-the-caret-package
layout(matrix(c(1,1,2)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
title('CONFUSION MATRIX', cex.main=2)
# create the matrix
rect(150, 430, 240, 370, col='#3F97D0')
text(195, 435, 'Class1', cex=1.2)
rect(250, 430, 340, 370, col='#F7AD50')
text(295, 435, 'Class2', cex=1.2)
text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
text(245, 450, 'Actual', cex=1.3, font=2)
rect(150, 305, 240, 365, col='#F7AD50')
rect(250, 305, 340, 365, col='#3F97D0')
text(140, 400, 'Class1', cex=1.2, srt=90)
text(140, 335, 'Class2', cex=1.2, srt=90)
# add in the cm results
res <- as.numeric(cm$table)
text(195, 400, res[1], cex=1.6, font=2, col='white')
text(195, 335, res[2], cex=1.6, font=2, col='white')
text(295, 400, res[3], cex=1.6, font=2, col='white')
text(295, 335, res[4], cex=1.6, font=2, col='white')
# add in the specifics
plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
# add in the accuracy information
text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}
bank = read.csv('../data/processed/BankChurners_filtered.csv', stringsAsFactors = T)
# Creating dummy variables for Education
bank$High_School <- ifelse(bank$Education_Level == 'High School', 1, 0)
bank$College <- ifelse(bank$Education_Level == 'College', 1, 0)
bank$Graduate <- ifelse(bank$Education_Level == 'Graduate', 1, 0)
bank$Uneducated <- ifelse(bank$Education_Level == 'Uneducated', 1, 0)
bank$Post_Graduate <- ifelse(bank$Education_Level == 'Post-Graduate', 1, 0)
bank$Doctorate <- ifelse(bank$Education_Level == 'Doctorate', 1, 0)
# Creating dummy variables for Marital Status
bank$Married <- ifelse(bank$Marital_Status == 'Married', 1, 0)
bank$Single <- ifelse(bank$Marital_Status == 'Single', 1, 0)
bank$Divorced <- ifelse(bank$Marital_Status == 'Divorced', 1, 0)
# Creating dummy variables for Gender
bank$Male <- ifelse(bank$Gender == 'M', 1, 0)
bank$Female <- ifelse(bank$Gender == 'F', 1, 0)
# Creating dummy variables for Income
bank$Income_5 <- ifelse(bank$Income_Category == '$120K +', 1, 0)
bank$Income_4 <- ifelse(bank$Income_Category == '$80K - $120K', 1, 0)
bank$Income_3 <- ifelse(bank$Income_Category == '$60K - $80K', 1, 0)
bank$Income_2 <- ifelse(bank$Income_Category == '$40K - $60K', 1, 0)
bank$Income_1 <- ifelse(bank$Income_Category == 'Less than $40K', 1, 0)
#Creating dummy variables for Card category
bank$Blue_Card <- ifelse(bank$Card_Category == 'Blue', 1, 0)
bank$Gold_Card <- ifelse(bank$Card_Category == 'Gold', 1, 0)
bank$Plat_Card <- ifelse(bank$Card_Category == 'Platinum', 1, 0)
bank$Silver_Card <- ifelse(bank$Card_Category == 'Silver', 1, 0)
bank <- bank[,c(-1,-2,-5,-7:-10)]
RNGkind (sample.kind = "Rounding")
set.seed(0)
dfls = partition.2(bank, 0.7)
test.data = dfls$data.test
training.data = dfls$data.train
set.seed(0)
modelLookup("rf")
train_control <- trainControl(method="cv", number=10)
rf <- train(Attrition_Flag ~ ., data = training.data, method = "rf", ntree = 50,rControl = train_control, tuneGrid = expand.grid(mtry = c(2,5,8)), metric = 'Kappa')
print(rf)
plot(varImp(rf))
rf$finalModel
# get prediction on the test data
pred.test.rf = predict(rf$finalModel, test.data, type = 'class')
# create confusion matrix
cm = confusionMatrix(pred.test.rf, test.data$Attrition_Flag, positive = "Attrited Customer")
confusion = data.frame(cm)
cm_plot = plot_cm(confusion)
cm_plot = plot_cm(cm)
plot_cm <- function(cm, plot_title) {#https://stackoverflow.com/questions/23891140/r-how-to-visualize-confusion-matrix-using-the-caret-package
layout(matrix(c(1,1,2)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
title(plot_title, cex.main=2)
# create the matrix
rect(150, 430, 240, 370, col='#3F97D0')
text(195, 435, 'Class1', cex=1.2)
rect(250, 430, 340, 370, col='#F7AD50')
text(295, 435, 'Class2', cex=1.2)
text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
text(245, 450, 'Actual', cex=1.3, font=2)
rect(150, 305, 240, 365, col='#F7AD50')
rect(250, 305, 340, 365, col='#3F97D0')
text(140, 400, 'Class1', cex=1.2, srt=90)
text(140, 335, 'Class2', cex=1.2, srt=90)
# add in the cm results
res <- as.numeric(cm$table)
text(195, 400, res[1], cex=1.6, font=2, col='white')
text(195, 335, res[2], cex=1.6, font=2, col='white')
text(295, 400, res[3], cex=1.6, font=2, col='white')
text(295, 335, res[4], cex=1.6, font=2, col='white')
# add in the specifics
plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
# add in the accuracy information
text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}
print(rf)
set.seed(0)
modelLookup("rf")
train_control <- trainControl(method="cv", number=10)
rf <- train(Attrition_Flag ~ ., data = training.data, method = "rf", ntree = 50,rControl = train_control, tuneGrid = expand.grid(mtry = c(8, 10, 12, 14)), metric = 'Kappa')
print(rf)
plot(varImp(rf))
rf$finalModel
# get prediction on the test data
pred.test.rf = predict(rf$finalModel, test.data, type = 'class')
# create confusion matrix
cm = confusionMatrix(pred.test.rf, test.data$Attrition_Flag, positive = "Attrited Customer")
cm_plot = plot_cm(cm, 'Confusion Matrix: Random Forest' )
cm_plot
set.seed(0)
modelLookup("rf")
train_control <- trainControl(method="cv", number=10)
rf <- train(Attrition_Flag ~ ., data = training.data, method = "rf", ntree = 50,rControl = train_control, tuneGrid = expand.grid(mtry = c(14, 18, 22)), metric = 'Kappa')
print(rf)
plot(varImp(rf))
rf$finalModel
# get prediction on the test data
pred.test.rf = predict(rf$finalModel, test.data, type = 'class')
# create confusion matrix
cm = confusionMatrix(pred.test.rf, test.data$Attrition_Flag, positive = "Attrited Customer")
cm_plot = plot_cm(cm, 'Confusion Matrix: Random Forest' )
cm_plot
print(ada)
modelLookup("ada")
set.seed(0)
train_control <- trainControl(method="cv", number=10)
tgrid <- expand.grid(iter = c(50,100,150),
maxdepth = c(1, 2, 3),
nu = c(0.1,0.2))
ada <- train(Attrition_Flag~ . , data = training.data, method = "ada", metric = "Kappa",
trControl = train_control, tuneGrid = tgrid)
print(ada)
plot(varImp(ada))
# get prediction on the test data
pred.test.ada = predict(ada$finalModel, test.data)
# create confusion matrix
cm = confusionMatrix(pred.test.ada, test.data$Attrition_Flag, positive = "Attrited Customer")
cm_plot = plot_cm(cm, 'Confusion Matrix: AdaBoost' )
cm_plot
ada$bestTune
modelLookup("ada")
set.seed(0)
train_control <- trainControl(method="cv", number=10)
tgrid <- expand.grid(iter = c(150),
maxdepth = c(3, 5, 7),
nu = c(0.2, 0.4))
ada <- train(Attrition_Flag~ . , data = training.data, method = "ada", metric = "Kappa",
trControl = train_control, tuneGrid = tgrid)
print(ada)
plot(varImp(ada))
# get prediction on the test data
pred.test.ada = predict(ada$finalModel, test.data)
# create confusion matrix
cm = confusionMatrix(pred.test.ada, test.data$Attrition_Flag, positive = "Attrited Customer")
cm_plot = plot_cm(cm, 'Confusion Matrix: AdaBoost' )
cm_plot
ada$bestTune
modelLookup("ada")
set.seed(0)
train_control <- trainControl(method="cv", number=10)
tgrid <- expand.grid(iter = c(150),
maxdepth = c(7, 9, 11),
nu = c(0.15, 0.2, 0.25))
ada <- train(Attrition_Flag~ . , data = training.data, method = "ada", metric = "Kappa",
trControl = train_control, tuneGrid = tgrid)
print(ada)
plot(varImp(ada))
# get prediction on the test data
pred.test.ada = predict(ada$finalModel, test.data)
# create confusion matrix
cm = confusionMatrix(pred.test.ada, test.data$Attrition_Flag, positive = "Attrited Customer")
cm_plot = plot_cm(cm, 'Confusion Matrix: AdaBoost' )
cm_plot
ada$bestTune
modelLookup("ada")
set.seed(0)
train_control <- trainControl(method="cv", number=10)
tgrid <- expand.grid(iter = c(150),
maxdepth = c(6, 7, 8),
nu = c(0.12, 0.15, 0.18))
ada <- train(Attrition_Flag~ . , data = training.data, method = "ada", metric = "Kappa",
trControl = train_control, tuneGrid = tgrid)
print(ada)
plot(varImp(ada))
# get prediction on the test data
pred.test.ada = predict(ada$finalModel, test.data)
# create confusion matrix
cm = confusionMatrix(pred.test.ada, test.data$Attrition_Flag, positive = "Attrited Customer")
cm_plot = plot_cm(cm, 'Confusion Matrix: AdaBoost' )
cm_plot
ada$bestTune
source('/Users/nickwawee/Desktop/BGSU/MSA_6440/Week_2/myfunctions.R')
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
source('/Users/nickwawee/Desktop/BGSU/MSA_6440/Week_2/myfunctions.R')
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
source('/Users/nickwawee/Desktop/BGSU/MSA_6440/Week_2/myfunctions.R')
data(Boston)
Boston$CAT.MEDV = ifelse(Boston$medv > 30, "1", "0" )
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
source('/Users/nickwawee/Desktop/BGSU/MSA_6440/Week_2/myfunctions.R')
data(Boston)
Boston$CAT.MEDV = ifelse(Boston$medv > 30, "1", "0" )
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
source('/Users/nickwawee/Desktop/BGSU/MSA_6440/Week_2/myfunctions.R')
data(Boston)
Boston$CAT.MEDV = ifelse(Boston$medv > 30, "1", "0" )
Boston$CAT.MEDV = as.factor(Boston$CAT.MEDV)
#partitioning
set.seed(0)
dfls = partition.2(Boston, 0.8)
test.data = dfls$data.test
training.data = dfls$data.train
colnames(Boston)
len(colnames(Boston))-1
length(colnames(Boston))-1
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(caret)
source('/Users/nickwawee/Desktop/BGSU/MSA_6440/Week_2/myfunctions.R')
data(Boston)
Boston$CAT.MEDV = ifelse(Boston$medv > 30, "1", "0" )
Boston$CAT.MEDV = as.factor(Boston$CAT.MEDV)
Boston = Boston[,-14]
#partitioning
set.seed(0)
dfls = partition.2(Boston, 0.8)
test.data = dfls$data.test
training.data = dfls$data.train
colnames(Boston)
train_control <- trainControl(method="cv", number=10)
## size refers to the number of hidden nodes and decay is the learning rate
tune.grid <- expand.grid(layer1 = seq(from = 0, to = 10, by = 2),
layer2 = seq(from = 0, to = 10, by = 2),
layer3 = seq(from = 0, to = 10, by = 2),
decay = seq(from = 0.1, to = 0.5, by = 0.1))
cv.nn <- train(CAT.MEDV ~ . , data = training.data, method = "mlpML",
preProc = c("center", "scale"),
trControl = train_control, tuneGrid = tune.grid)
?caret
train_control <- trainControl(method="cv", number=10)
## size refers to the number of hidden nodes and decay is the learning rate
tune.grid <- expand.grid(layer1 = seq(from = 0, to = 10, by = 2),
layer2 = seq(from = 0, to = 10, by = 2),
layer3 = seq(from = 0, to = 10, by = 2))
cv.nn <- train(CAT.MEDV ~ . , data = training.data, method = "mlpML",
preProc = c("center", "scale"),
trControl = train_control, tuneGrid = tune.grid)
train_control <- trainControl(method="cv", number=10)
## size refers to the number of hidden nodes and decay is the learning rate
tune.grid <- expand.grid(layer1 = seq(from = 1, to = 10, by = 1),
layer2 = seq(from = 1, to = 10, by = 1),
layer3 = seq(from = 1, to = 10, by = 1))
cv.nn <- train(CAT.MEDV ~ . , data = training.data, method = "mlpML",
preProc = c("center", "scale"),
trControl = train_control, tuneGrid = tune.grid)
cv.nn$bestTune
